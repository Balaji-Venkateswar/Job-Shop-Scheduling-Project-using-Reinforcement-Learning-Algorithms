# Job-Shop-Scheduling-Project-using-Reinforcement-Learning-Algorithms
The project deals with the Job shop scheduling environment in which there are two robots (agents) Robot 1 and Robot 2 and six work stations namely two input stations IB1 and IB2 through which the workpiece 1 (WP1) and workpiece 2 (WP2) enters the system, three processing stations S1, S2 and S3 and an output station OB. 
#
The robots (agents) perform the actions on two different workpieces WP1 and WP2. Each workpiece has a defined route through the stations. The Workpiece 1 start from IB1 input station and pass-through stations S1, S2 and S3 and comes out through OB. Similarly, WP2 start from IB2 input station and pass-through stations S2, S3 and S1 and comes out through output station OB. 
#
As the workpieces WP1 and WP2 travel through different stations due to the actions performed by the robots, the state of the environment gets altered for each action and the current state is decided based upon the current position of the workpieces in the environment.
#
The state space of the environment provides the information about the current position of workpieces in the environment. The state space is a number pattern with '0', '1' and '2' arranged in three digits for the three stations. '0' defines no WP and '1' defines WP1 and '2' defined WP2. As there are 3 processing stations and two workpieces, a total of 27 state space combinations is possible.The above mentioned production cycle is effectively automated through Machine Learning algorithms. SARSA and Advantage Actor Critic are reinforcement algorithms, that is implemented to train the machine to perform sequence of operations.
